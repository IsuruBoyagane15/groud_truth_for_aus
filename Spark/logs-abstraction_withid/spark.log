{"0": "17/06/09 * INFO mapred.SparkHadoopMapRedUtil attempt_*: Committed", "1": "17/06/09 * INFO storage.MemoryStore Block * stored as bytes in memory (estimated size *, free *)", "2": "17/06/09 * INFO storage.MemoryStore Block * stored as values in memory (estimated size *, free *)", "3": "17/06/09 * INFO spark.SecurityManager Changing modify acls to: *", "4": "17/06/09 * INFO spark.SecurityManager Changing view acls to: *", "5": "17/06/09 20:10:42 INFO executor.CoarseGrainedExecutorBackend Connecting to driver: spark://*", "6": "17/06/09 20:10:41 INFO storage.DiskBlockManager Created local directory at *", "7": "17/06/09 * INFO output.FileOutputCommitter File Output Committer Algorithm version is *", "8": "17/06/09 * INFO executor.Executor Finished task * in stage * (TID *). * bytes result sent to driver", "9": "17/06/09 * INFO storage.BlockManager Found block rdd_* locally", "10": "17/06/09 * INFO executor.CoarseGrainedExecutorBackend Got assigned task *", "11": "17/06/09 * INFO rdd.HadoopRDD Input split: hdfs://*", "12": "17/06/09 20:10:47 INFO Configuration.deprecation mapred.job.id is deprecated. Instead, use mapreduce.job.id", "13": "17/06/09 20:10:47 INFO Configuration.deprecation mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id", "14": "17/06/09 20:10:47 INFO Configuration.deprecation mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap", "15": "17/06/09 20:10:47 INFO Configuration.deprecation mapred.task.partition is deprecated. Instead, use mapreduce.task.partition", "16": "17/06/09 20:10:47 INFO Configuration.deprecation mapred.tip.id is deprecated. Instead, use mapreduce.task.id", "17": "17/06/09 20:10:41 INFO storage.MemoryStore MemoryStore started with capacity * GB", "18": "17/06/09 * INFO spark.CacheManager Partition rdd_* not found, computing it", "19": "17/06/09 * INFO broadcast.TorrentBroadcast Reading broadcast variable * took * ms", "20": "17/06/09 20:10:42 INFO storage.BlockManagerMaster Registered BlockManager", "21": "17/06/09 20:10:40 INFO executor.CoarseGrainedExecutorBackend Registered signal handlers for [TERM, HUP, INT]", "22": "17/06/09 20:10:41 INFO Remoting Remoting started; listening on addresses :[akka.tcp://*]", "23": "17/06/09 * INFO executor.Executor Running task * in stage * (TID *)", "24": "17/06/09 * INFO output.FileOutputCommitter Saved output of task 'attempt_*' to hdfs://*", "25": "17/06/09 * INFO spark.SecurityManager SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, curi); users with modify permissions: Set(yarn, curi)", "26": "17/06/09 20:10:42 INFO netty.NettyBlockTransferService Server created on *", "27": "17/06/09 20:10:41 INFO slf4j.Slf4jLogger Slf4jLogger started", "28": "17/06/09 * INFO broadcast.TorrentBroadcast Started reading broadcast variable *", "29": "17/06/09 20:10:42 INFO executor.Executor Starting executor ID * on host *", "30": "17/06/09 20:10:41 INFO Remoting Starting remoting", "31": "17/06/09 20:10:42 INFO executor.CoarseGrainedExecutorBackend Successfully registered with driver", "32": "17/06/09 20:10:42 INFO util.Utils Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port *.", "33": "17/06/09 20:10:41 INFO util.Utils Successfully started service 'sparkExecutorActorSystem' on port *.", "34": "17/06/09 * INFO python.PythonRunner Times: total = *, boot = *, init = *, finish = *", "35": "17/06/09 20:10:42 INFO storage.BlockManagerMaster Trying to register BlockManager"}